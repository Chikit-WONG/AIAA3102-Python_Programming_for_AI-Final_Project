项目 A：小语言模型微调（分类 / 生成任务）
主题与定位
聚焦参数高效微调（PEFT），针对真实场景任务（客户支持邮件分类 / 自动回复生成），平衡计算成本与落地价值。
核心目标（必须完成）
搭建全流程 pipeline：数据加载 / 清洗→分词→训练 / 验证集划分→LoRA 微调→早停与 checkpointing。
报告标准指标：分类任务需提准确率 / F1（含置信区间），生成任务需 ROUGE-L+LLM-as-Judge 评估（≥20 样本，自定义评分标准）。
控制过拟合：对比超参数（学习率、权重衰减等），用 Matplotlib 可视化损失 / 指标曲线。
进阶方向（至少选 2 个）
数据驱动变体：主动采样或数据增强，结合统计测试对比结果。
泛化能力验证：零样本 / 少样本 / 微调效果对比，或训练样本量与性能相关性分析。
效率对比：QLoRA（4/8 位）与全精度微调的训练时间、内存占用差异。
安全鲁棒性：测试毒性 / 提示注入风险，提供缓解方案（如过滤模板）。
交付物
可复现代码 + 配置文件 + 详细 README。
6-8 页报告（含问题、方法、消融实验、结果、失效模式）。
≤3 分钟预录演示 + 周 13 答辩。


